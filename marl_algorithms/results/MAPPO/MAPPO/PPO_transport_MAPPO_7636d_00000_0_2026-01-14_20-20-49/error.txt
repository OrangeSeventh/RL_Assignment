Failure # 1 (occurred at 2026-01-14_20-20-54)
The actor died because of an error raised in its creation task, [36mray::PPO.__init__()[39m (pid=82480, ip=172.26.29.125, actor_id=f7c2e2942a2a5d7913f68c7501000000, repr=PPO)
  File "/root/RL_Assignment/venv/lib/python3.11/site-packages/ray/rllib/evaluation/worker_set.py", line 227, in _setup
    self.add_workers(
  File "/root/RL_Assignment/venv/lib/python3.11/site-packages/ray/rllib/evaluation/worker_set.py", line 593, in add_workers
    raise result.get()
  File "/root/RL_Assignment/venv/lib/python3.11/site-packages/ray/rllib/utils/actor_manager.py", line 481, in __fetch_result
    result = ray.get(r)
             ^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^
ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, [36mray::RolloutWorker.__init__()[39m (pid=82537, ip=172.26.29.125, actor_id=b58d900ce3dc36e9135e679801000000, repr=<ray.rllib.evaluation.rollout_worker.RolloutWorker object at 0x7d7aa631bb90>)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/RL_Assignment/venv/lib/python3.11/site-packages/ray/rllib/evaluation/rollout_worker.py", line 470, in __init__
    self.policy_dict, self.is_policy_to_train = self.config.get_multi_agent_setup(
                                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/RL_Assignment/venv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm_config.py", line 2956, in get_multi_agent_setup
    raise ValueError(
ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!

During handling of the above exception, another exception occurred:

[36mray::PPO.__init__()[39m (pid=82480, ip=172.26.29.125, actor_id=f7c2e2942a2a5d7913f68c7501000000, repr=PPO)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/RL_Assignment/venv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py", line 517, in __init__
    super().__init__(
  File "/root/RL_Assignment/venv/lib/python3.11/site-packages/ray/tune/trainable/trainable.py", line 169, in __init__
    self.setup(copy.deepcopy(self.config))
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/root/RL_Assignment/venv/lib/python3.11/site-packages/ray/rllib/algorithms/algorithm.py", line 639, in setup
    self.workers = WorkerSet(
                   ^^^^^^^^^^
  File "/root/RL_Assignment/venv/lib/python3.11/site-packages/ray/rllib/evaluation/worker_set.py", line 179, in __init__
    raise e.args[0].args[2]
ValueError: `observation_space` not provided in PolicySpec for default_policy and env does not have an observation space OR no spaces received from other workers' env(s) OR no `observation_space` specified in config!
